---
layout: default
title: "Lights Under Attack: Stress-Testing Noise-Coded Illumination"
---

# **Lights Under Attack: Stress-Testing Noise-Coded Illumination**

<!-- *A concise, descriptive title for your project.* -->

<!-- ![Project Banner](./assets/img/banner-placeholder.png)  
<sub>*(Optional: Replace with a conceptual figure or meaningful image.)*</sub> -->

---

## üìù **Abstract**

Noise-Coded Illumination (NCI) is recognized for its potential to provide robust forensic authentication for video footage. Existing research has demonstrated its capability to embed and recover temporal watermarks, creating a powerful asymmetry against manipulators. However, there remains limited exploration into the resilience of NCI against informed adversarial attacks, where an attacker with knowledge of the system attempts to bypass detection. This project aims to assess the security of NCI by evaluating several attack strategies under realistic conditions. Our work will implement a baseline NCI pipeline and systematically test adversarial bypass methods, analyzing their success and proposing potential countermeasures to guide the secure deployment of this promising technology.

---

## üë• **Team**

- Maxwell Jung (<maxwelljung@ucla.edu>, [GitHub](https://github.com/MaxwellJung))  
- Wentao Chen (<wentac4@ucla.edu>, [GitHub](https://github.com/wentac4))  
- Steve Zang (<zangbruin007@ucla.edu>, [GitHub](https://github.com/SteveZ-Cal))  

---

## üìë **Documentation**

- [Midterm Checkpoint Slides](https://docs.google.com/presentation/d/1JbTUeoli6I7b-AFx3gMX-jX8nmnHsw5_VxXokDmLpW4/edit?usp=sharing)  
- [Final Presentation Slides](https://docs.google.com/presentation/d/1eZMDApG3otnrJUzfvpvx2tNXskiX9aYgf0qJhQyEvnM/edit?usp=sharing)
- [Final Report](./report.html)


